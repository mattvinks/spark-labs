{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching in SQL -- Part 2\n",
    "Understand Spark SQL caching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Read JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "clickstreamDF = spark.read.json(\"/data/click-stream/json\")\n",
    "t2 = time.perf_counter()\n",
    "print (\"Read JSON in {:,.2f} ms \".format( (t2-t1)*1000))\n",
    "\n",
    "clickstreamDF.createOrReplaceTempView(\"clickstream\")\n",
    "print (\"registered temp table clickstream\")\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Query without caching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "sql=\"\"\"\n",
    "select domain, count(*) as total from clickstream\n",
    "group by domain \n",
    "order by total \n",
    "desc limit 10\n",
    "\"\"\"\n",
    "top10_domains = spark.sql(sql)\n",
    "top10_domains.show()\n",
    "t2 = time.perf_counter()\n",
    "print (\"query took {:,.2f} ms \".format( (t2-t1)*1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Explain Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_domains.explain()\n",
    "\n",
    "#top10_domains.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Cache\n",
    "\n",
    "There are 3 ways to cache\n",
    "1. dataframe.cache()  : non blocking\n",
    "2. spark.sql(\"cache table TABLE_NAME\") : blocking\n",
    "3. spark.catalog.cacheTable('tableName') : non blocking\n",
    "\n",
    "Try all these options and see the performance implications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# uncache\n",
    "spark.catalog.clearCache() ## clear all tables\n",
    "# spark.catalog.uncacheTable(\"clickstream\")  # clear just one table\n",
    "\n",
    "print (\"is 'clickstream' cached : \" , spark.catalog.isCached('clickstream'))\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "## we have different ways to cache,\n",
    "## uncomment one of the following\n",
    "#spark.sql(\"cache table clickstream\");  ## 1\n",
    "#clickstreamDF.cache()  ## 2\n",
    "spark.catalog.cacheTable(\"clickstream\") ## 3\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "print (\"caching took {:,.2f} ms \".format( (t2-t1)*1000))\n",
    "\n",
    "print (\"is 'clickstream' cached : \" , spark.catalog.isCached('clickstream'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step : Query after caching\n",
    "Run the following cell to measure query time after caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Query after caching\n",
    "\n",
    "import time\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "sql=\"\"\"\n",
    "select domain, count(*) as total from clickstream\n",
    "group by domain \n",
    "order by total \n",
    "desc limit 10\n",
    "\"\"\"\n",
    "top10_domains = spark.sql(sql)\n",
    "top10_domains.show()\n",
    "t2 = time.perf_counter()\n",
    "print (\"query took {:,.2f} ms \".format( (t2-t1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step : Explain Query\n",
    "You will see caching in effect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_domains.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Cache\n",
    "Try the following ways to clear cache\n",
    "\n",
    "1. spark.sql (\"CLEAR CACHE\")  - removes all cache\n",
    "2. spark.sql (\"CLEAR CACHE tableName\") - removes one table\n",
    "3. spark.catalog.unCacheTable('tableName') - removes one cached table\n",
    "4. spark.catalog.clearCache() - clear all caches\n",
    "5. dataframe.unPersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"clear cache\")\n",
    "# spark.catalog.clearCacheTable('table name')\n",
    "# df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
