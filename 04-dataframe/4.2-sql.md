<link rel='stylesheet' href='../assets/css/main.css'/>

[<< back to main index](../README.md)

Lab 4.2 : Spark SQL : SQL
================================


### Overview
Using SQL statements with Spark SQL.   
[Standalone lab](4.2-sql.md) |   [Hadoop lab](4.2H-spark-sql-hadoop.md)

### Depends On
None

### Run time
20-30 mins


----------------------------
STEP 1: Start Spark Shell
----------------------------
Change working directory to `spark-labs`.  This way, we can access data using relative paths (makes life simpler)

```bash
    $  cd ~/spark-labs
    $   ~/spark/bin/spark-shell
```


### STEP 2: Load Clickstream data

**==> Create a dataframe**  

```scala
    val clickstreamDF = spark.read.json("data/click-stream/clickstream.json")
```


**==> Register dataframe as a table**

```scala

    clickstreamDF.createOrReplaceTempView("clickstream")
```

### Step 3: See all tables
Use [spark.catalog](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.catalog.Catalog) class

Output may look like this:
```scala
  spark.catalog.listTables.show
```

```console
+-----------+--------+-----------+---------+-----------+
|       name|database|description|tableType|isTemporary|
+-----------+--------+-----------+---------+-----------+
|clickstream|    null|       null|TEMPORARY|       true|
+-----------+--------+-----------+---------+-----------+
```

We see 'clickstream' is registered as a TEMP table.


### STEP 4: Querying using SQL


**==> Select all logs**
```scala
    val logs = spark.sql("select * from clickstream")
    // 'logs' is a dataframe

    logs.show
```

Output might be like

    +-------+-----------+----+-----------------+----+----------+-------------+------+
    | action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|
    +-------+-----------+----+-----------------+----+----------+-------------+------+
    |clicked|campaign_19| 118|      youtube.com|ip_4|session_36|1420070400000|user_9|
    |blocked|campaign_12|   5|     facebook.com|ip_3|session_96|1420070400864|user_5|
    |clicked| campaign_3|  54|sf.craigslist.org|ip_9|session_61|1420070401728|user_8|
    ...


**==> Find records with only clicks**

**==> Count records from each domain, sort the output by most to least**

### STEP 4: Joining Datasets

**==> Load `domains` dataset and register it to table `domains`**  

```scala
    val domainsDF = spark.read.json("data/click-stream/domain-info.json")
    domainsDF.show
    domainsDF.createOrReplaceTempView("domains")
```

**==> Join `clickstreams` and `domains`**    
Hint : Join query syntax for joining two tables A, B

```sql
    spark.sql("select A.*, B.* from A  join B  ON (A.x = B.y)")
```

**

**==> Count traffic per domain category (news, social ..etc)**    
Hint : query the joined datasets

### STEP 5: Explore UI
(Your DAG visualization may be slightly different from what we show here)

<img src="../assets/images/5.2c.png" style="border: 5px solid grey; max-width:100%;"/>

<img src="../assets/images/5.2d.png" style="border: 5px solid grey; max-width:100%;"/>

<img src="../assets/images/5.2e.png" style="border: 5px solid grey; max-width:100%;"/>
