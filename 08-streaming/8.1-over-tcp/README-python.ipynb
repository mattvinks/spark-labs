{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8.1 - Spark Streaming Using Network Sockets\n",
    "\n",
    "\n",
    "### Overview\n",
    "Build a simple Spark streaming app consuming data over TCP socket\n",
    "\n",
    "### Depends On\n",
    "None\n",
    "\n",
    "### Run time\n",
    "30-40 mins\n",
    "\n",
    "\n",
    "## STEP 1: Go to project directory\n",
    "```bash\n",
    "$ cd ~/spark-labs/08-streaming/8.1-over-tcp/python\n",
    "```\n",
    "\n",
    "## Step 2 : Edit file : [python/over-tcp.py](python/over-tcp.py)\n",
    "**Fix TODO-1 and TODO-2**\n",
    "\n",
    "\n",
    "## Step 3: Run Netcat Server to start network traffic\n",
    "\n",
    "Open another terminal into Spark node (terminal #2)\n",
    "\n",
    "Use `nc` command to move text you type in terminal #2 to port 10000\n",
    "Open an terminal and run this command at prompt\n",
    "\n",
    "```bash\n",
    "$ nc -lk 10000\n",
    "\n",
    "\n",
    "# if this shows 'Port already in use', get the process id and kill the process\n",
    "# $ sudo netstat -plnt | grep 10000\n",
    "# Process id will be shown in output\n",
    "# $ sudo kill -9 <process id>\n",
    "```\n",
    "\n",
    "## Step4: Run the streaming application\n",
    "\n",
    "```bash\n",
    "# be in project root directory\n",
    "$   cd  ~/spark-labs/08-streaming/8.1-over-tcp/python\n",
    "$   ~/spark/bin/spark-submit --master local[2] --driver-class-path ../logging/ over-tcp.py\n",
    "```\n",
    "\n",
    "Lets call this Terminal #1\n",
    "\n",
    "Also note --master url `local[2]`\n",
    "* We are using a local 'embedded' server  (quick for development)\n",
    "* And we need at least 2 cpu cores -- one for receiver (long running task) and another for our program.  \n",
    "If only allocated one core `local[1]`  the program will have run-time errors or won't run!\n",
    "\n",
    "## Step5: Test by typing text in the terminal\n",
    "\n",
    "Enter some text in netcat terminal (terminal #2)\n",
    "\n",
    "```\n",
    "a\n",
    "b\n",
    "```\n",
    "\n",
    "Inspect the output from Spark streaming (terminal #1)\n",
    "\n",
    "You should see something similar to this screen shot.\n",
    "(Click on the image for larger version)   \n",
    "\n",
    "<a href=\"../../assets/images/8.1a.png\"><img src=\"../../assets/images/8.1a.png\" style=\"border: 5px solid grey; max-width:100%;\"/></a>\n",
    "\n",
    "**=>  Hit Ctrl+C  on terminal #1 to kill Spark streaming application**\n",
    "\n",
    "## Step6: Filter (TODO-3)\n",
    "**==>  Edit file :  [python/over-tcp.py](python/over-tcp.py)**  \n",
    "**==> Uncomment block around TODO-3, to filter lines that has the word 'xyz'**\n",
    "\n",
    "```bash\n",
    "## TODO-3 : filter for lines that has 'xyz'\n",
    "x = lines.filter(lambda line : \"xyz\" in line)\n",
    "x.pprint()\n",
    "```\n",
    "**==> Run the code**\n",
    "\n",
    "```bash\n",
    "$    cd ~/spark-labs/08-streaming/8.1-over-tcp/python  \n",
    "$    ~/spark/bin/spark-submit --master local[2] --driver-class-path ../logging/ over-tcp.py\n",
    "```\n",
    "\n",
    "Using 'netcat' program, send some data to streaming.  Make sure some data has the text 'xyz'\n",
    "\n",
    "```console\n",
    "a\n",
    "b xyz\n",
    "```\n",
    "\n",
    "Output may look like this:\n",
    "\n",
    "<a href=\"../../assets/images/8.1b\"><img src=\"../../assets/images/8.1b.png\" style=\"border: 5px solid grey; max-width:100%;\"/></a>\n",
    "\n",
    "## Step 7: Save data into files (TODO-4)\n",
    "\n",
    "**==> Edit file : `over-tcp.py`**\n",
    "**Uncomment TODO-4 code block so it looks like this**\n",
    "\n",
    "```bash\n",
    "## TODO-4 : save the output in a file\n",
    "blocked.saveAsTextFiles(\"out\")\n",
    "```\n",
    "\n",
    "**=> Run the program**\n",
    "```bash\n",
    "$ ~/spark/bin/spark-submit --master local[2] --driver-class-path logging/ over-tcp.py\n",
    "```\n",
    "\n",
    "**=> Send some data through netcat window (terminal #2)**\n",
    "\n",
    "**=> Hit Contrl+C in terminal #2 to terminate Spark streaming**\n",
    "\n",
    "**=> Inspect the `out-blocked` directory**\n",
    "\n",
    "```bash\n",
    "$   ls -l\n",
    "```\n",
    "\n",
    "Output may look like this:\n",
    "\n",
    "```console\n",
    "drwxr-xr-x 4 sujee staff 136 Jan 22 22:42 out-blocked-1485153750000/\n",
    "drwxr-xr-x 8 sujee staff 272 Jan 22 22:42 out-blocked-1485153760000/\n",
    "drwxr-xr-x 6 sujee staff 204 Jan 22 22:42 out-blocked-1485153770000/\n",
    "drwxr-xr-x 4 sujee staff 136 Jan 22 22:55 out-blocked-1485154510000/\n",
    "drwxr-xr-x 4 sujee staff 136 Jan 22 22:55 out-blocked-1485154520000/\n",
    "```\n",
    "\n",
    "**=> Inspect some files, what do you see?**\n",
    "\n",
    "```bash\n",
    "# you may need to adjust the file name\n",
    "$ find out-blocked*\n",
    "```\n",
    "\n",
    "Output may look like this:\n",
    "\n",
    "```console\n",
    "out-blocked-1485153760000/_SUCCESS\n",
    "out-blocked-1485153760000/part-00000\n",
    "out-blocked-1485153760000/part-00001\n",
    "out-blocked-1485153770000\n",
    "out-blocked-1485153770000/._SUCCESS.crc\n",
    "out-blocked-1485153770000/.part-00000.crc\n",
    "out-blocked-1485153770000/_SUCCESS\n",
    "out-blocked-1485153770000/part-00000\n",
    "```\n",
    "\n",
    "Files\n",
    "* part-0000 : this is data\n",
    "* _SUCCESS_ : indicates that directory is complete\n",
    "* crc : Checksum files\n",
    "\n",
    "## Bonus Lab  1 : Extract BLOCKED IPs\n",
    "**==> Edit file :  `over-tcp.py`**  \n",
    "\n",
    "**==> Fix BONUS-LAB to extract blocked IPs**\n",
    "\n",
    "**==> Run a program like this**\n",
    "\n",
    "```bash\n",
    "$ ~/spark/bin/spark-submit --master local[2] --driver-class-path logging/ over-tcp.py\n",
    "```\n",
    "\n",
    "**==> Test with this clickstream data, using netcat window**\n",
    "\n",
    "```\n",
    "1420070400000,ip_1,user_5,clicked,facebook.com,campaign_6,139,session_98\n",
    "1420070400864,ip_2,user_3,viewed,facebook.com,campaign_4,35,session_98\n",
    "1420070401728,ip_8,user_8,clicked,youtube.com,campaign_12,115,session_92\n",
    "1420070402592,ip_1,user_2,blocked,wikipedia.org,campaign_5,129,session_91\n",
    "1420070403456,ip_7,user_7,viewed,funnyordie.com,campaign_11,12,session_13\n",
    "```\n",
    "\n",
    "## Bonus Lab  2 : Network Word Count\n",
    "**==> Inspect file : networkwordcount.py**\n",
    "\n",
    "**==> Run a program like this**\n",
    "```bash\n",
    "$ ~/spark/bin/spark-submit --master local[2] --driver-class-path logging/ networkwordcount.py\n",
    "```\n",
    "\n",
    "**==> Test with data using NC**\n",
    "```bash\n",
    "$ nc -lk 10000\n",
    "a b c\n",
    "a\n",
    "b c\n",
    "d\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
