{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "<< [back to main index](../README.md) \n",
    "\n",
    "Lab 3.4: Map Reduce\n",
    "===================\n",
    "### Overview\n",
    "Learn MapReduce in Spark step by step\n",
    "\n",
    "### Depends On \n",
    "None\n",
    "\n",
    "### Run time\n",
    "20 mins\n",
    "\n",
    "\n",
    "--------------------------\n",
    "STEP 1: Make an RDD\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "input = [\"hello world\", \"good bye world\", \"ok bye\"]\n",
    "r = sc.parallelize(input)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Add up the words and counts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Add up the words and counts here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------\n",
    "STEP 2 : Map\n",
    "------------\n",
    "**=> Apply `map()` function to rdd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2 = r.map(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Print out the results by `collect()`**  \n",
    "**=> Notice the resulting RDD type**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Print out the results by collect.\n",
    "\n",
    "# What is the type of the RDD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------\n",
    "STEP 3: flatMap\n",
    "---------------\n",
    "**=> Use `flatMap` to create another RDD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = r.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Print out the results, can you explain the data type**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Print out r3 and explain data type\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------------------\n",
    "STEP 4: Create KV pair\n",
    "----------------------\n",
    "**=> Create a key-value pair by using `flatMap` and `map`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r4 = r.flatMap(lambda line: line.split(\" \")).map(lambda word:(word, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "STEP 5: reduceByKey\n",
    "-------------------\n",
    "**=> Add up the words and counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r5 = r4.reduceByKey(lambda a,b: a+b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: view results of r5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "STEP 6:  Generating data\n",
    "------------------------\n",
    "If you haven't done so yet,  generate some 'twinkle' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "  $   cd  ~/spark-labs/data/twinkle\n",
    "  $   ./create-data-files.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will generate a bunch of data files at various sizes (1M, 10M, 100M, 500M and 1G)\n",
    "Verify the data files and their sizes by doing a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$   ls -lh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use these files as input\n",
    "\n",
    "\n",
    "------------------------\n",
    "STEP 7:  Do wordcount on larger file\n",
    "------------------------\n",
    "Load one of the larger files (100M + )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Do wordcount on 100M file.\n",
    "\n",
    "f = sc.textFile(\"file path\")  # Enter file path\n",
    "# do the wordcount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
